import json
import os
from typing import List, Dict, Any
import chromadb
from chromadb.config import Settings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.llms import Ollama

from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain.schema import Document
import logging


# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class STBTesterRAG:
    def __init__(
        self,
        ollama_base_url: str = "http://localhost:11434",
        model_name: str = "qwen3:8b",  # Mod√®le optimis√© pour les t√¢ches de g√©n√©ration de code
        persist_directory: str = "./chroma_db",
    ):
        """
        Initialise le pipeline RAG pour STBTester

        Args:
            ollama_base_url: URL de base d'Ollama
            model_name: Nom du mod√®le √† utiliser
            persist_directory: R√©pertoire de persistance ChromaDB
        """
        self.ollama_base_url = ollama_base_url
        self.model_name = model_name
        self.persist_directory = persist_directory

        # Initialisation des composants
        self._init_embeddings()
        self._init_llm()
        self._init_vectorstore()
        self._init_qa_chain()

    def _init_embeddings(self):
        """Initialise les embeddings Ollama"""
        try:
            self.embeddings = OllamaEmbeddings(
                base_url=self.ollama_base_url,
                model="nomic-embed-text",  # Mod√®le d'embedding efficace
            )
            logger.info("‚úÖ Embeddings initialis√©s")
        except Exception as e:
            logger.error(f" Erreur initialisation embeddings: {e}")
            raise

    def _init_llm(self):
        """Initialise le LLM Ollama"""
        try:
            self.llm = Ollama(
                base_url=self.ollama_base_url,
                model=self.model_name,
                temperature=0.1,  # Temp√©rature basse pour plus de consistance
                top_p=0.9,
                num_ctx=4096,  # Contexte large pour les scripts longs
            )
            logger.info(f"‚úÖ LLM {self.model_name} initialis√©")
        except Exception as e:
            logger.error(f" Erreur initialisation LLM: {e}")
            raise

    def _init_vectorstore(self):
        """Initialise ChromaDB"""
        try:
            # Configuration ChromaDB
            chroma_settings = Settings(
                persist_directory=self.persist_directory, anonymized_telemetry=False
            )

            self.vectorstore = None
            logger.info("‚úÖ ChromaDB initialis√©")
        except Exception as e:
            logger.error(f" Erreur initialisation ChromaDB: {e}")
            raise

    def _init_qa_chain(self):
        """Initialise la cha√Æne QA"""
        # Template de prompt sp√©cialis√© pour STBTester
        # 5. Ajoute des commentaires explicatifs
        self.prompt_template = PromptTemplate(
            input_variables=["context", "question"],
            template="""Tu es un expert en automatisation de tests STBTester pour la plateforme Totalplay.
            
Utilise UNIQUEMENT les informations du contexte fourni pour g√©n√©rer un script Python STBTester.

CONTEXTE:
{context}

DEMANDE:
{question}

INSTRUCTIONS:
1. G√©n√®re un script Python complet et fonctionnel
2. Utilise EXACTEMENT les m√™mes fonctions que dans les exemples du contexte
3. Respecte la structure et les patterns des scripts existants
4. Inclus tous les imports n√©cessaires
5. Assure-toi que le script soit pr√™t √† l'ex√©cution

SCRIPT PYTHON STBTester:
```python""",
        )

    def load_test_cases_data(self, json_data: Dict[str, Any]):
        """
        Charge les cas de test depuis un dictionnaire JSON et les ins√®re dans la vectorstore
        """
        documents = []

        for case in json_data.get("test_cases", []):
            content = self._format_test_case_content(case)
            metadata = {
                "id": case.get("id"),
                "title": case.get("title"),
                "application": case.get("application"),
                "category": case.get("category"),
            }
            doc = Document(page_content=content, metadata=metadata)
            documents.append(doc)

        if not documents:
            raise ValueError("Aucun document √† ins√©rer dans la vectorstore.")

        # Cr√©ation de la vectorstore avec les documents
        self.vectorstore = Chroma.from_documents(
            documents=documents, embedding=self.embeddings, persist_directory="db"
        )

        print(f" {len(documents)} cas de test charg√©s dans la vectorstore.")

    def _prepare_documents(self, json_data: Dict[str, Any]) -> List[Document]:
        """
        Pr√©pare les documents √† partir des donn√©es JSON

        Args:
            json_data: Donn√©es JSON des cas de test

        Returns:
            Liste de documents LangChain
        """
        documents = []

        # Document g√©n√©ral avec informations du dataset
        dataset_info = json_data.get("dataset_info", {})
        dataset_doc = Document(
            page_content=f"""
Dataset: {dataset_info.get('name', '')}
Description: {dataset_info.get('description', '')}
Applications: {', '.join(dataset_info.get('applications', []))}
Cat√©gories: {', '.join(dataset_info.get('categories', []))}
            """.strip(),
            metadata={"type": "dataset_info"},
        )
        documents.append(dataset_doc)

        # Documents pour chaque cas de test
        for test_case in json_data.get("test_cases", []):
            # Contenu principal du cas de test
            content = self._format_test_case_content(test_case)

            # M√©tadonn√©es enrichies
            metadata = {
                "id": test_case.get("id", ""),
                "title": test_case.get("title", ""),
                "category": test_case.get("category", ""),
                "application": test_case.get("application", ""),
                "complexity": test_case.get("complexity", ""),
                "type": "test_case",
            }

            doc = Document(page_content=content, metadata=metadata)
            documents.append(doc)

            # Document s√©par√© pour le code
            if test_case.get("code_snippet"):
                code_content = f"""
Test Case: {test_case.get('title', '')}
Application: {test_case.get('application', '')}
Category: {test_case.get('category', '')}

CODE SNIPPET:
{test_case['code_snippet']}

FUNCTIONS USED:
{', '.join(test_case.get('functions_used', []))}

PATTERNS:
{', '.join(test_case.get('patterns', []))}
                """.strip()

                code_doc = Document(
                    page_content=code_content,
                    metadata={**metadata, "type": "code_snippet"},
                )
                documents.append(code_doc)

        return documents

    def _format_test_case_content(self, test_case: Dict[str, Any]) -> str:
        """Formate le contenu d'un cas de test"""
        content_parts = [
            f"ID: {test_case.get('id', '')}",
            f"Titre: {test_case.get('title', '')}",
            f"Application: {test_case.get('application', '')}",
            f"Cat√©gorie: {test_case.get('category', '')}",
            f"Complexit√©: {test_case.get('complexity', '')}",
            f"Dur√©e estim√©e: {test_case.get('estimated_duration', '')}",
            f"Objectif: {test_case.get('objective', '')}",
            f"Pr√©requis: {test_case.get('preconditions', '')}",
        ]

        # √âtapes
        if test_case.get("steps"):
            content_parts.append("\n√âtapes:")
            for step in test_case["steps"]:
                step_text = f"  {step.get('step_number', '')}: {step.get('action', '')}"
                if step.get("expected_result"):
                    step_text += f" ‚Üí {step['expected_result']}"
                if step.get("code_equivalent"):
                    step_text += f" [{step['code_equivalent']}]"
                content_parts.append(step_text)

        # Informations techniques
        if test_case.get("functions_used"):
            content_parts.append(
                f"\nFonctions utilis√©es: {', '.join(test_case['functions_used'])}"
            )

        if test_case.get("navigation_path"):
            content_parts.append(
                f"Chemin de navigation: {test_case['navigation_path']}"
            )

        if test_case.get("tags"):
            content_parts.append(f"Tags: {', '.join(test_case['tags'])}")

        return "\n".join(content_parts)

    def setup_qa_chain(self):
        """Configure la cha√Æne QA avec le retriever"""
        if not self.vectorstore:
            raise ValueError("Vectorstore non initialis√©. Chargez d'abord les donn√©es.")

        retriever = self.vectorstore.as_retriever(
            search_type="mmr",  # Maximum Marginal Relevance
            search_kwargs={
                "k": 5,  # Top 5 documents les plus pertinents
                "fetch_k": 10,  # R√©cup√®re 10 docs puis s√©lectionne 5
                "lambda_mult": 0.7,  # Balance diversit√©/similarit√©
            },
        )

        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=retriever,
            chain_type_kwargs={"prompt": self.prompt_template},
            return_source_documents=True,
        )

        logger.info(" Cha√Æne QA configur√©e")

    def generate_script(self, user_query: str) -> Dict[str, Any]:
        """
        G√©n√®re un script STBTester bas√© sur la requ√™te utilisateur, avec contexte enrichi

        Args:
            user_query: Description du test souhait√©

        Returns:
            Dictionnaire avec le script g√©n√©r√© et les sources
        """
        if not hasattr(self, "qa_chain"):
            self.setup_qa_chain()

        try:
            # R√©cup√®re plusieurs cas de test similaires pour enrichir le contexte
            similar_tests = self.search_similar_tests(user_query, k=5)
            context = "\n\n".join([doc["content"] for doc in similar_tests])
            # Ex√©cution de la requ√™te avec contexte enrichi
            result = self.qa_chain({"query": user_query, "context": context})

            # Extraction du script Python du r√©sultat
            script = self._extract_python_script(result["result"])

            # Informations sur les sources utilis√©es
            sources = []
            for doc in result.get("source_documents", []):
                sources.append(
                    {
                        "content": doc.page_content[:200] + "...",
                        "metadata": doc.metadata,
                    }
                )

            return {
                "script": script,
                "raw_response": result["result"],
                "sources": sources,
                "query": user_query,
            }

        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration script: {e}")
            raise

    def _extract_python_script(self, response: str) -> str:
        """Extrait le code Python de la r√©ponse"""
        # Cherche le code entre ```python et ```
        if "```python" in response:
            start = response.find("```python") + 9
            end = response.find("```", start)
            if end != -1:
                return response[start:end].strip()

        # Si pas de markdown, retourne la r√©ponse compl√®te
        return response.strip()

    def search_similar_tests(self, query: str, k: int = 3) -> List[Dict[str, Any]]:
        """
        Recherche des tests similaires

        Args:
            query: Requ√™te de recherche
            k: Nombre de r√©sultats

        Returns:
            Liste des tests similaires
        """
        if not self.vectorstore:
            raise ValueError("Vectorstore non initialis√©")

        docs = self.vectorstore.similarity_search(query, k=k)
        results = []

        for doc in docs:
            results.append(
                {
                    "content": doc.page_content,
                    "metadata": doc.metadata,
                    "relevance_score": "High",  # ChromaDB ne retourne pas de score par d√©faut
                }
            )

        return results


def main():
    """Fonction principale de d√©monstration pour RAG avec data_youtube_all.json et Ollama local (qwen3:8b)"""
    import json
    import os

    # Chemin vers le fichier de dataset fusionn√©
    data_path = os.path.join("data", "data_youtube_all.json")
    output_dir = os.path.join("generated_tests", "youtube")
    os.makedirs(output_dir, exist_ok=True)

    # Chargement du fichier JSON
    with open(data_path, "r", encoding="utf-8") as f:
        json_data = json.load(f)

    try:
        # Initialisation du pipeline RAG
        print(" Initialisation du pipeline RAG STBTester...")
        rag = STBTesterRAG()

        # Chargement des donn√©es
        print(" Chargement des cas de test...")
        rag.load_test_cases_data(json_data)

        # Configuration de la cha√Æne QA
        print(" Configuration de la cha√Æne QA...")
        rag.setup_qa_chain()

        # Exemples de sc√©narios mixtes √† tester
        scenarios = [
            "Lancer netflix depuis le menu STREAMING, naviguer √† droite deux fois, attendre 10 secondes, puis quitter proprement l‚Äôapplication."
            # "Ouvrir YouTube, lancer une vid√©o, puis toutes les 5 minutes naviguer vers le bas et attendre 30 minutes au total avant de quitter.",
            # "D√©marrer YouTube, attendre le chargement, v√©rifier qu‚Äôil n‚Äôy a pas d‚Äô√©cran noir pendant 1 heure, puis sortir de l‚Äôapplication.",
            # "Aller sur YouTube via STREAMING, naviguer √† droite et en bas, attendre 20 secondes, puis revenir au menu principal.",
            # "Lancer YouTube, naviguer dans plusieurs directions (haut, bas, droite, gauche) en boucle pendant 10 minutes, puis quitter."
        ]

        for i, query in enumerate(scenarios, 1):
            print(f"\nüéØ G√©n√©ration d'un script de test pour le sc√©nario mixte {i}...")
            result = rag.generate_script(query)
            print(f"\nSc√©nario: {query}")
            print("=" * 50)
            print(result["script"])
            print("=" * 50)
            # Sauvegarde du script g√©n√©r√© dans un fichier d√©di√©
            script_filename = os.path.join(output_dir, f"test_youtube_scenario_{i}.py")
            with open(script_filename, "w", encoding="utf-8") as f_script:
                f_script.write(result["script"])
            print(f"\n‚úÖ Script sauvegard√© dans : {script_filename}")
            print(f"\nüìö Sources utilis√©es: {len(result['sources'])}")
            for j, source in enumerate(result["sources"][:2]):
                print(f"  {j+1}. {source['metadata'].get('title', 'N/A')}")

    except Exception as e:
        print(f"Erreur: {e}")


if __name__ == "__main__":
    main()
